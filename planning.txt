Planning Document

Finished:
  Active speech-to-text
  Basic text-to-speech

Steps:
  Get basic text-to-action nlp working
    Figure out how to organize wit.ai training
      Not sure about whether to group everything into the 'intent' entity or to make unique entities
      'intent' seems to help for having multiple entities in one query
    Figure out how to have multiple entities within one query
  Develop cli app to the same "work-level" as the audio app
  Develop server/app architecture
    Look at developing core server engine in rust
    Farm out app and tool development to python
      How are the "actions" going to be handled (they should be apps in their own right)
  Set aside some time to learn how to perform speech recognition/nlp stuff on my own

Issues:
  The STT/TTS stack is not very stable
    Prone to crashes/Possibility of cross-interference

Initial Goal:
  Be able to open a program on my computer using voice (using custom AI)
  Be able to ask my computer the weather using my voice
  Control Spotify using voice only (this will actually be somewhat difficult)

Broad Planning:
  Sort of want an Alexa/Cortana style system across all of my devices
    Help with planning/reminders/etc.
    Unify all of my devices under a central planning system (smart home/computers/etc.)
  One neat thing would be to send "documents" across devices
    "Send this to my laptop" and then current focus of the desktop will open on the laptop at the next time
  Going to want it to be very extensible
    Say I get a smart lock
    I want to be able to plug it in, say "lock the door" and have the door lock
  How conversational do I want it to be?
    At the beginning it may not be that conversational (but the technology will improve a lot)

Broad Description:
  Unified computer organization and interaction system
  Open and work on a file on one computer, then finish and close it on another
  Completely interactable with an Alexa style voice interface and artificial intelligence
